from sparktts.models.audio_tokenizer import BiCodecTokenizer

model_dir = '/home/yueyulin/models/Spark-TTS-0.5B/'
device = 'cuda:3'
audio_tokenizer = BiCodecTokenizer(model_dir, device)

data = {"language": "zh", "text": "我们可以尝试制作一个梦想相册，将我们的愿望啊以图片的形式贴在里面，每天都来翻看，让自己的潜意识不断的受到刺激。", "speaker": "ZH_B00000_S09992", "global_tokens": [1963, 1778, 1200, 4068, 482, 1262, 3312, 408, 3850, 3864, 595, 3160, 741, 3368, 3251, 1275, 1277, 3329, 2206, 4031, 10, 2260, 1935, 2881, 1067, 2856, 3573, 333, 2673, 343, 3908, 687], "semantic_tokens": [284, 1990, 458, 2506, 6642, 2864, 3560, 8115, 2593, 4275, 6159, 2299, 4935, 6643, 1050, 2631, 1168, 4543, 5485, 3474, 2134, 6793, 8110, 4705, 2364, 3266, 3376, 910, 900, 80, 612, 4470, 149, 3092, 2600, 7405, 5825, 1556, 7770, 5317, 6343, 7548, 3059, 1566, 6050, 850, 8012, 5778, 811, 7406, 4403, 3114, 8019, 2688, 1956, 6747, 4211, 3052, 4828, 3711, 4169, 4828, 2826, 4057, 5753, 1530, 3265, 1488, 5996, 5467, 7441, 1550, 5237, 2154, 4567, 7958, 354, 4304, 4184, 644, 7975, 7163, 6053, 4933, 768, 6634, 3853, 3441, 6790, 6207, 73, 1231, 4827, 7978, 3461, 6538, 4878, 8043, 2699, 6154, 6391, 1174, 2820, 5571, 3183, 3541, 5883, 6707, 7261, 7493, 7668, 4503, 7386, 7037, 7005, 1365, 7223, 6160, 1574, 2298, 6309, 7819, 4571, 6638, 6980, 2108, 1101, 1115, 2544, 5575, 2946, 4407, 1743, 4841, 7203, 7926, 3503, 5060, 5691, 4999, 6702, 6853, 2616, 2981, 592, 6584, 4359, 7477, 5332, 974, 7285, 7902, 2192, 1455, 3511, 3354, 1810, 4626, 3927, 127, 3387, 5001, 3281, 3162, 2169, 398, 3562, 4205, 2296, 5564, 5217, 777, 5626, 6015, 3854, 734, 5645, 7089, 7742, 2629, 1593, 6731, 2829, 5949, 5746, 5023, 2238, 6874, 4358, 949, 7312, 5086, 6677, 4321, 2664, 500, 7315, 6268, 3225, 3074, 7435, 2293, 2079, 2761, 1729, 7775, 3953, 5185, 4215, 6204, 5123, 4074, 7004, 4543, 5607, 7956, 5348, 1576, 1716, 3320, 6489, 347, 3066, 956, 1459, 5500, 4796, 246, 6552, 7313, 3409, 2296, 659, 2309, 5756, 4154, 6536, 110, 4234, 1300, 7362, 2510, 3120, 1271, 6709, 2165, 7131, 5453, 59, 2451, 6895, 7515, 5644, 8149, 3162, 309, 1696, 5819, 3813, 3167, 7579, 8047, 7891, 2687, 638, 169, 8016, 5206, 4328, 3098, 959, 4927, 4579, 8093, 6846, 1852, 7696, 5309, 1532, 7001, 306, 184, 6422, 6773, 2058, 4401, 2785, 1503, 6979, 7411, 3973, 7659, 94, 6069, 4247, 1678, 4400, 2921, 5828, 1047, 8063, 1949, 5023, 803, 6212, 7965, 7678, 6887, 3142, 6561, 2631, 7066, 2364, 3851, 7409, 1063, 3114, 56, 7011, 5771, 743, 3666, 5718, 6012, 3011, 7538, 5317, 4615, 2752, 3168, 2800, 5220, 2481, 4483, 4044, 2693, 6505, 219, 4475, 5642, 4686, 3583, 1152, 8125, 52, 836, 4623, 4845, 6302, 3285, 7643, 899, 5293, 6797, 7438, 7691, 4207, 8004, 4454, 6932, 7196, 2347, 7664, 7322, 821, 2570, 3527, 7377, 3377, 7162, 2, 4795, 2755, 4946, 2973, 7727]}
import torch
global_tokens = [3415, 2100, 1534, 3771, 2998, 1182, 2120, 2401, 3898, 2358, 1165, 3515, 1022, 3380, 3249, 2610, 4091, 4089, 157, 2879, 3089, 1332, 2763, 2441, 2117, 270, 3563, 2624, 3628, 2562, 2515, 3106]
semantic_tokens = [284, 1990, 458, 2506, 6642, 2864, 3560, 8115, 2593, 4275, 6159, 2299, 4935, 6643, 1050, 2631, 1168, 4543, 5485, 3474, 2134, 6793, 8110, 4705, 2364, 3266, 3376, 910, 900, 80, 612, 4470, 149, 3092, 2600, 7405, 5825, 1556, 7770, 5317, 6343, 7548, 3059, 1566, 6050, 850, 8012, 5778, 811, 7406, 4403, 3114, 8019, 2688, 1956, 6747, 4211, 3052, 4828, 3711, 4169, 4828, 2826, 4057, 5753, 1530, 3265, 1488, 5996, 5467, 7441, 1550, 5237, 2154, 4567, 7958, 354, 4304, 4184, 644, 7975, 7163, 6053, 4933, 768, 6634, 3853, 3441, 6790, 6207, 73, 1231, 4827, 7978, 3461, 6538, 4878, 8043, 2699, 6154, 6391, 1174, 2820, 5571, 3183, 3541, 5883, 6707, 7261, 7493, 7668, 4503, 7386, 7037, 7005, 1365, 7223, 6160, 1574, 2298, 6309, 7819, 4571, 6638, 6980, 2108, 1101, 1115, 2544, 5575, 2946, 4407, 1743, 4841, 7203, 7926, 3503, 5060, 5691, 4999, 6702, 6853, 2616, 2981, 592, 6584, 4359, 7477, 5332, 974, 7285, 7902, 2192, 1455, 3511, 3354, 1810, 4626, 3927, 127, 3387, 5001, 3281, 3162, 2169, 398, 3562, 4205, 2296, 5564, 5217, 777, 5626, 6015, 3854, 734, 5645, 7089, 7742, 2629, 1593, 6731, 2829, 5949, 5746, 5023, 2238, 6874, 4358, 949, 7312, 5086, 6677, 4321, 2664, 500, 7315, 6268, 3225, 3074, 7435, 2293, 2079, 2761, 1729, 7775, 3953, 5185, 4215, 6204, 5123, 4074, 7004, 4543, 5607, 7956, 5348, 1576, 1716, 3320, 6489, 347, 3066, 956, 1459, 5500, 4796, 246, 6552, 7313, 3409, 2296, 659, 2309, 5756, 4154, 6536, 110, 4234, 1300, 7362, 2510, 3120, 1271, 6709, 2165, 7131, 5453, 59, 2451, 6895, 7515, 5644, 8149, 3162, 309, 1696, 5819, 3813, 3167, 7579, 8047, 7891, 2687, 638, 169, 8016, 5206, 4328, 3098, 959, 4927, 4579, 8093, 6846, 1852, 7696, 5309, 1532, 7001, 306, 184, 6422, 6773, 2058, 4401, 2785, 1503, 6979, 7411, 3973, 7659, 94, 6069, 4247, 1678, 4400, 2921, 5828, 1047, 8063, 1949, 5023, 803, 6212, 7965, 7678, 6887, 3142, 6561, 2631, 7066, 2364, 3851, 7409, 1063, 3114, 56, 7011, 5771, 743, 3666, 5718, 6012, 3011, 7538, 5317, 4615, 2752, 3168, 2800, 5220, 2481, 4483, 4044, 2693, 6505, 219, 4475, 5642, 4686, 3583, 1152, 8125, 52, 836, 4623, 4845, 6302, 3285, 7643, 899, 5293, 6797, 7438, 7691, 4207, 8004, 4454, 6932, 7196, 2347, 7664, 7322, 821, 2570, 3527, 7377, 3377, 7162, 2, 4795, 2755, 4946, 2973, 7727]
# global_tokens = torch.tensor(data["global_tokens"]).unsqueeze(0).to(device)
# semantic_tokens = torch.tensor(data["semantic_tokens"]).unsqueeze(0).to(device)
global_tokens = torch.tensor(global_tokens).unsqueeze(0).to(device)
semantic_tokens = torch.tensor(semantic_tokens).unsqueeze(0).to(device)
wav_reconstructed = audio_tokenizer.detokenize(global_tokens, semantic_tokens)

import soundfile as sf
sf.write("from_spark_audio_tokens.wav", wav_reconstructed, audio_tokenizer.config['sample_rate'])