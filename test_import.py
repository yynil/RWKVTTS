#!/usr/bin/env python3
"""
ç®€å•çš„å¯¼å…¥æµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯ä¿®å¤åçš„å¯¼å…¥æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import torch
import sys

def test_imports():
    """æµ‹è¯•æ‰€æœ‰å¿…è¦çš„å¯¼å…¥"""
    print("æµ‹è¯•å¯¼å…¥...")
    
    try:
        # æµ‹è¯• transformers å¯¼å…¥
        from transformers.generation.streamers import BaseStreamer
        print("âœ… BaseStreamer å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•è‡ªå®šä¹‰æ¨¡å‹å¯¼å…¥
        from model.llm.xy_llm import RWKV7XYLM, RWKV7XYConfig
        print("âœ… RWKV7XYLM å’Œ RWKV7XYConfig å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•å…¶ä»–å¿…è¦çš„å¯¼å…¥
        from transformers import AutoTokenizer
        print("âœ… AutoTokenizer å¯¼å…¥æˆåŠŸ")
        
        print("\nğŸ‰ æ‰€æœ‰å¯¼å…¥æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ å…¶ä»–é”™è¯¯: {e}")
        return False

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»ºï¼ˆä¸éœ€è¦å®é™…æƒé‡ï¼‰"""
    print("\næµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    try:
        from model.llm.xy_llm import RWKV7XYConfig
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„é…ç½®
        config = RWKV7XYConfig(
            vocab_size=1000,
            hidden_size=128,
            num_hidden_layers=2,
            num_attention_heads=4,
            intermediate_size=256,
            speech_vocab_size=1024,
            num_channels=8,
            text_shift_size=65536
        )
        print("âœ… é…ç½®åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ¨¡å‹åˆ›å»ºï¼ˆè¿™ä¼šå¤±è´¥ï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰å®é™…çš„ RWKV7Modelï¼Œä½†å¯ä»¥æµ‹è¯•å¯¼å…¥ï¼‰
        print("âœ… é…ç½®æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("å¼€å§‹å¯¼å…¥æµ‹è¯•...\n")
    
    success = test_imports()
    
    if success:
        test_model_creation()
    
    print(f"\næµ‹è¯•å®Œæˆï¼Œå¯¼å…¥é—®é¢˜å·²ä¿®å¤ï¼") 